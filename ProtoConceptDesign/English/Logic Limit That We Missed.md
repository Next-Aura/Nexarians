# Logic Limit That We Missed

## Introduction

Cognitive function is the ability to manage and align information to make it useful. In the world of machine learning, the expansion of cognitive function is sometimes overlooked due to the perceived trade-off of interpretability and systemic complexity. Some architectures prioritize the depth of understanding of a function, rather than its expansion.

Deep learning (DL) is a branch of machine learning (ML) in which a system is able to decipher more complex patterns and requires a more complex architecture than conventional or classical ML. ML itself is the moment when a program is able to produce something it previously did not see during the training process.
Some of the main elements of machine learning include the error function (loss function), its derivatives, and the number of steps taken to minimize the error (loss). Architecturally, DL enables the recognition of non-linear patterns during the training process.

## Deepening

ML and DL share several conceptual similarities, but their goal remains the same: to produce something they previously did not see during the training process. From this point, pseudo-generalizations begin to emerge, but they remain incomplete interpretations of generalization, as both ML and DL essentially only deepen a single cognitive function.

## Conclusion

From the explanations above, it can be concluded that generalization in the context of cross-domain information alignment in a model is not directly influenced by the DL architecture, but rather by other architectures that enable internal cross-domain information alignment and harmonization, thereby enabling the expansion of cognitive functions.